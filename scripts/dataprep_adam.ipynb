{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamkovacs/env/lib/python3.9/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data prep (1) edgelist w/ home-home distance\n",
    "output : geo_edgelist_top50.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follower network -- data\n",
    "edgelist = pd.read_csv('../data/usageousers_city_follower_networks.rpt.gz')\n",
    "\n",
    "# read in data about individuals -- data2\n",
    "userinfo = pd.read_csv('../data/usageousers_data_export_with_tract_geoid_top50.csv.gz', index_col=0)\n",
    "user_geo = userinfo.loc[:,[\"user_id\", \"lat_home\", \"lon_home\", \"lat_work\", \"lon_work\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edgelist with geoinfo\n",
    "edgelist = pd.merge(pd.merge(edgelist, user_geo, left_on=\"user_id1\", right_on=\"user_id\", how=\"left\"),\\\n",
    "               user_geo, left_on=\"user_id2\", right_on=\"user_id\", how=\"left\", suffixes=(\"1\", \"2\"))\n",
    "\n",
    "# remove duplicate columns\n",
    "edgelist = edgelist.loc[:,~edgelist.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 390.20663619041443 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# DISTANCE - home-home part\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# geometry cols\n",
    "edgelist[\"geometry1\"] = edgelist.apply(lambda r: Point(r[\"lon_home1\"],r[\"lat_home1\"]), axis=1)\n",
    "edgelist[\"geometry2\"] = edgelist.apply(lambda r: Point(r[\"lon_home2\"],r[\"lat_home2\"]), axis=1)\n",
    "\n",
    "geo_edgelist = gpd.GeoDataFrame(edgelist)\n",
    "\n",
    "# change crs\n",
    "geo_edgelist = geo_edgelist.set_geometry('geometry2')\n",
    "geo_edgelist.crs = {'init': 'epsg:4326'}\n",
    "geo_edgelist = geo_edgelist.to_crs({'init': 'epsg:3857'})\n",
    "\n",
    "geo_edgelist = geo_edgelist.set_geometry('geometry1')\n",
    "geo_edgelist.crs = {'init': 'epsg:4326'}\n",
    "geo_edgelist = geo_edgelist.to_crs({'init': 'epsg:3857'})\n",
    "\n",
    "# set geometry\n",
    "geo_edgelist = geo_edgelist.set_geometry('geometry1')\n",
    "\n",
    "# home-home distance calculation\n",
    "geo_edgelist['dist_hh'] = geo_edgelist['geometry1'].distance(geo_edgelist['geometry2'])\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 428.23562598228455 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# DISTANCE - work-work part\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# geometry cols\n",
    "edgelist[\"geometry1\"] = edgelist.apply(lambda r: Point(r[\"lon_work1\"],r[\"lat_work1\"]), axis=1)\n",
    "edgelist[\"geometry2\"] = edgelist.apply(lambda r: Point(r[\"lon_work2\"],r[\"lat_work2\"]), axis=1)\n",
    "\n",
    "geo_edgelist2 = gpd.GeoDataFrame(edgelist)\n",
    "\n",
    "# change crs\n",
    "geo_edgelist2 = geo_edgelist2.set_geometry('geometry2')\n",
    "geo_edgelist2.crs = {'init': 'epsg:4326'}\n",
    "geo_edgelist2 = geo_edgelist2.to_crs({'init': 'epsg:3857'})\n",
    "\n",
    "geo_edgelist2 = geo_edgelist2.set_geometry('geometry1')\n",
    "geo_edgelist2.crs = {'init': 'epsg:4326'}\n",
    "geo_edgelist2 = geo_edgelist2.to_crs({'init': 'epsg:3857'})\n",
    "\n",
    "# set geometry\n",
    "geo_edgelist2 = geo_edgelist2.set_geometry('geometry1')\n",
    "\n",
    "# home-home distance calculation\n",
    "geo_edgelist2['dist_ww'] = geo_edgelist2['geometry1'].distance(geo_edgelist2['geometry2'])\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine..\n",
    "temp = geo_edgelist2.loc[:,[\"cbsacode\", \"user_id1\", \"user_id2\", \"dist_ww\"]]\n",
    "geo_edgelist = pd.merge(geo_edgelist, temp, on=[\"cbsacode\", \"user_id1\", \"user_id2\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point, save the data!!\n",
    "export = geo_edgelist.drop(columns=['geometry1', 'geometry2'])\n",
    "export.to_csv(\"../data/geo_edgelist_top50.csv.gz\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data prep (2) degree around home and tract info\n",
    "output : degree_tab_top50.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census data\n",
    "census = pd.read_csv('../data/censusdata_top50_2012.csv')\n",
    "\n",
    "# short names for cbsas\n",
    "names = pd.read_csv('../data/cbsacode_shortname_tracts.csv', sep = \";\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create tract geoids\n",
    "def create_geoid(row):\n",
    "    state = str(int(row[\"state\"])).zfill(2)\n",
    "    county = str(int(row[\"county\"])).zfill(3)\n",
    "    tract = str(int(row[\"tract\"])).zfill(6)\n",
    "    return \"14000US\" +state+county+tract\n",
    "\n",
    "census['geoid'] = census.apply(create_geoid,axis=1)\n",
    "\n",
    "# add names\n",
    "census = pd.merge(census, names, on='geoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamkovacs/env/lib/python3.9/site-packages/pyproj/crs/crs.py:131: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n"
     ]
    }
   ],
   "source": [
    "# geojson data, converted to geopandas dataframe\n",
    "tract_geoms = gpd.GeoDataFrame.from_features(\n",
    "    [json.loads(e.strip('\\n')) for e in open('../data/censustract_geoms_top50.geojson').readlines()]\n",
    ")\n",
    "\n",
    "# change projection\n",
    "init_crs = 4326 # lon,lat\n",
    "project_crs = 3857 # Cartesian systems\n",
    "tract_geoms.crs = {'init': 'epsg:' + str(init_crs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge census data and geometries of tracts\n",
    "tract_data = pd.merge(census[['geoid', 'cbsacode', 'short_name', 'population', 'education_bachelor', 'income']],\\\n",
    "    tract_geoms[['geometry', 'full_geoid']],\\\n",
    "    left_on='geoid', right_on='full_geoid', how='left')\n",
    "\n",
    "# drop those tracts where income < $1000\n",
    "tract_data = tract_data[(tract_data['income']>1000)]\n",
    "\n",
    "# median income by cbsacode\n",
    "tract_data['income_median'] = tract_data['cbsacode'].map(tract_data.groupby('cbsacode')['income'].median().to_dict())\n",
    "poor = (tract_data['income'] < tract_data[\"income_median\"])\n",
    "tract_data['poor'] = poor.astype(int).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable manipulation\n",
    "tract_data['log_income'] = np.log(tract_data['income'])\n",
    "tract_data['log_population'] = np.log(tract_data['population'])\n",
    "tract_data['BA_share'] = tract_data['education_bachelor']/ tract_data['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data about individuals -- userinfo - filter on geoinfo -- user_geo\n",
    "userinfo = pd.read_csv('../data/usageousers_top50_common_data.csv.gz', index_col=0)\n",
    "user_geo = userinfo.loc[:,[\"user_id\", \"lat_home\", \"lon_home\"]]\n",
    "\n",
    "# geometry col\n",
    "user_geo[\"geometry_h\"] = user_geo.apply(lambda r: Point(r[\"lon_home\"],r[\"lat_home\"]), axis=1)\n",
    "\n",
    "# edgelist with distance\n",
    "geo_edgelist = pd.read_csv(\"../data/geo_edgelist_top50_adam.csv.gz\")\n",
    "\n",
    "# filter on important columns\n",
    "geo_edgelist = geo_edgelist[[\"user_id1\", \"user_id2\", \"dist_hh\" ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin distances\n",
    "binsize=500\n",
    "geo_edgelist[\"dh_bin\"] = binsize * (geo_edgelist[\"dist_hh\"] / binsize).map(int) + 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree table -- NOTE -- all ties are mutual\n",
    "degree_tab = geo_edgelist.groupby(\"user_id1\")[\"user_id2\"].count().reset_index()\n",
    "degree_tab.columns = [\"user_id\", \"degree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove users with less than 10 ties (!!!)\n",
    "degree_tab = degree_tab[degree_tab[\"degree\"] >= 10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop -- degree at distance around HOME\n",
    "for d in list(range(500, 10500, 500)):\n",
    "    \n",
    "    temp = geo_edgelist.loc[geo_edgelist.dh_bin == d,:].groupby(\"user_id1\")[\"user_id2\"].count().reset_index()\n",
    "    temp.columns = [\"user_id\", (\"d\"+str(d))]\n",
    "    \n",
    "    degree_tab = pd.merge(degree_tab, temp, on=\"user_id\", how=\"left\")\n",
    "\n",
    "# replace NA with 0\n",
    "degree_tab = degree_tab.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop -- cummulative degree around HOME\n",
    "for d in list(range(500, 10500, 500)):\n",
    "    \n",
    "    temp = geo_edgelist.loc[geo_edgelist.dh_bin <= d,:].groupby(\"user_id1\")[\"user_id2\"].count().reset_index()\n",
    "    temp.columns = [\"user_id\", (\"dcum\"+str(d))]\n",
    "    \n",
    "    degree_tab = pd.merge(degree_tab, temp, on=\"user_id\", how=\"left\")\n",
    "\n",
    "# replace NA with 0\n",
    "degree_tab = degree_tab.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the share of each degree\n",
    "for c in list(degree_tab.columns[22:,]):    \n",
    "    degree_tab[str(c) + \"_share\"] = round((degree_tab[str(c)] / degree_tab[\"degree\"]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add user geoinfo\n",
    "degree_tab = pd.merge(degree_tab, user_geo, on=\"user_id\", how=\"left\")\n",
    "degree_tab = gpd.GeoDataFrame(degree_tab)\n",
    "degree_tab = degree_tab.set_geometry('geometry_h')\n",
    "degree_tab.crs = {'init': 'epsg:' + str(init_crs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join\n",
    "tract_data = gpd.GeoDataFrame(tract_data)\n",
    "tract_data = tract_data.set_geometry('geometry')\n",
    "degree_tab = gpd.sjoin(degree_tab, tract_data[['geometry', 'poor', 'cbsacode', 'short_name']], 'left', 'within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86862"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(degree_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86242"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "86821 - 579"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "degree_tab = degree_tab.dropna(subset=[\"short_name\"])   # here we lost around 579 / 86.821 users\n",
    "degree_tab.drop(columns=[\"index_right\", \"geometry_h\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column reorder\n",
    "cols = degree_tab.columns.tolist()\n",
    "dcols = cols[1:62]\n",
    "newcols = [\"user_id\", \"cbsacode\", \"short_name\", \"poor\",\"lat_home\", \"lon_home\"] + dcols\n",
    "degree_tab = degree_tab[newcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86242"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(degree_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cbsacode</th>\n",
       "      <th>short_name</th>\n",
       "      <th>poor</th>\n",
       "      <th>lat_home</th>\n",
       "      <th>lon_home</th>\n",
       "      <th>degree</th>\n",
       "      <th>d500</th>\n",
       "      <th>d1000</th>\n",
       "      <th>d1500</th>\n",
       "      <th>...</th>\n",
       "      <th>dcum5500_share</th>\n",
       "      <th>dcum6000_share</th>\n",
       "      <th>dcum6500_share</th>\n",
       "      <th>dcum7000_share</th>\n",
       "      <th>dcum7500_share</th>\n",
       "      <th>dcum8000_share</th>\n",
       "      <th>dcum8500_share</th>\n",
       "      <th>dcum9000_share</th>\n",
       "      <th>dcum9500_share</th>\n",
       "      <th>dcum10000_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>41860.0</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.780</td>\n",
       "      <td>-122.410</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>35620.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.717</td>\n",
       "      <td>-73.956</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>293</td>\n",
       "      <td>41860.0</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.762</td>\n",
       "      <td>-122.418</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>294</td>\n",
       "      <td>42660.0</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.653</td>\n",
       "      <td>-122.356</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>364</td>\n",
       "      <td>14460.0</td>\n",
       "      <td>Boston</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.369</td>\n",
       "      <td>-71.154</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86816</th>\n",
       "      <td>994290314</td>\n",
       "      <td>19740.0</td>\n",
       "      <td>Denver</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.673</td>\n",
       "      <td>-104.782</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86817</th>\n",
       "      <td>994365709</td>\n",
       "      <td>35620.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.785</td>\n",
       "      <td>-72.949</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86818</th>\n",
       "      <td>998305572</td>\n",
       "      <td>15380.0</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.913</td>\n",
       "      <td>-78.798</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86819</th>\n",
       "      <td>1000525465</td>\n",
       "      <td>13820.0</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.623</td>\n",
       "      <td>-86.662</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86820</th>\n",
       "      <td>1003203037</td>\n",
       "      <td>37980.0</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.989</td>\n",
       "      <td>-75.098</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86242 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  cbsacode     short_name  poor  lat_home  lon_home  degree  \\\n",
       "1              21   41860.0  San Francisco   1.0    37.780  -122.410      49   \n",
       "2              47   35620.0       New York   0.0    40.717   -73.956      59   \n",
       "3             293   41860.0  San Francisco   1.0    37.762  -122.418      10   \n",
       "4             294   42660.0        Seattle   0.0    47.653  -122.356      11   \n",
       "5             364   14460.0         Boston   0.0    42.369   -71.154      29   \n",
       "...           ...       ...            ...   ...       ...       ...     ...   \n",
       "86816   994290314   19740.0         Denver   1.0    39.673  -104.782      10   \n",
       "86817   994365709   35620.0       New York   1.0    40.785   -72.949      24   \n",
       "86818   998305572   15380.0        Buffalo   1.0    42.913   -78.798      23   \n",
       "86819  1000525465   13820.0     Birmingham   0.0    33.623   -86.662      18   \n",
       "86820  1003203037   37980.0   Philadelphia   1.0    39.989   -75.098      13   \n",
       "\n",
       "       d500  d1000  d1500  ...  dcum5500_share  dcum6000_share  \\\n",
       "1       1.0    2.0    1.0  ...           0.633           0.653   \n",
       "2       0.0    6.0    1.0  ...           0.492           0.576   \n",
       "3       3.0    1.0    1.0  ...           0.900           0.900   \n",
       "4       0.0    1.0    0.0  ...           0.364           0.455   \n",
       "5       0.0    0.0    0.0  ...           0.207           0.241   \n",
       "...     ...    ...    ...  ...             ...             ...   \n",
       "86816   0.0    2.0    1.0  ...           0.700           0.700   \n",
       "86817   0.0    2.0    2.0  ...           0.375           0.375   \n",
       "86818   0.0    0.0    5.0  ...           0.435           0.478   \n",
       "86819   0.0    0.0    0.0  ...           0.333           0.389   \n",
       "86820   0.0    2.0    3.0  ...           0.769           0.769   \n",
       "\n",
       "       dcum6500_share  dcum7000_share  dcum7500_share  dcum8000_share  \\\n",
       "1               0.653           0.653           0.653           0.653   \n",
       "2               0.695           0.763           0.797           0.814   \n",
       "3               0.900           0.900           0.900           0.900   \n",
       "4               0.455           0.455           0.545           0.545   \n",
       "5               0.345           0.414           0.483           0.483   \n",
       "...               ...             ...             ...             ...   \n",
       "86816           0.700           0.700           0.700           0.700   \n",
       "86817           0.375           0.375           0.375           0.375   \n",
       "86818           0.565           0.609           0.696           0.696   \n",
       "86819           0.389           0.389           0.444           0.444   \n",
       "86820           0.769           0.769           0.769           0.769   \n",
       "\n",
       "       dcum8500_share  dcum9000_share  dcum9500_share  dcum10000_share  \n",
       "1               0.653           0.653           0.673            0.673  \n",
       "2               0.847           0.864           0.881            0.898  \n",
       "3               0.900           0.900           0.900            0.900  \n",
       "4               0.545           0.727           0.727            0.727  \n",
       "5               0.517           0.552           0.586            0.655  \n",
       "...               ...             ...             ...              ...  \n",
       "86816           0.700           0.700           0.800            0.800  \n",
       "86817           0.375           0.417           0.458            0.458  \n",
       "86818           0.696           0.739           0.870            0.913  \n",
       "86819           0.444           0.444           0.444            0.444  \n",
       "86820           0.769           0.769           0.769            0.769  \n",
       "\n",
       "[86242 rows x 67 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_tab.to_csv(\"../data/degree_tab_top50_adam.csv.gz\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point, save the data!!\n",
    "degree_tab.to_csv(\"../data/degree_tab_top50.csv.gz\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data prep (3) local clustering around home\n",
    "output : clust_tab_top50.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reopen degree_tab\n",
    "degree_tab = pd.read_csv(\"../data/degree_tab_top50_adam.csv.gz\")\n",
    "users = list(set(list(degree_tab[\"user_id\"])))\n",
    "\n",
    "# edgelist with distance\n",
    "geo_edgelist = pd.read_csv(\"../data/geo_edgelist_top50_adam.csv.gz\")\n",
    "geo_edgelist = geo_edgelist[[\"user_id1\", \"user_id2\", \"dist_hh\" ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3909.105551958084 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# clustering around HOME\n",
    "start_time = time.time()\n",
    "\n",
    "temp_list = []\n",
    "\n",
    "for user in users:\n",
    "    time.sleep(.005)\n",
    "    r = {}\n",
    "    r['user_id'] = user\n",
    "    for dist in [1000, 3000, 5000, 10000]:\n",
    "        # get third edges\n",
    "        lista = list(geo_edgelist[(geo_edgelist['user_id1'] == user) & (geo_edgelist['dist_hh'] <= dist)]['user_id2'])\n",
    "        if len(lista) < 2:   # in case the user does not have at least 2 connections\n",
    "            r['clust' + str(dist)] = np.nan\n",
    "        else:\n",
    "            a = geo_edgelist[geo_edgelist['user_id1'].isin(lista)]\n",
    "            b = a[a['user_id2'].isin(lista)][['user_id1', 'user_id2']]\n",
    "            # get df with ego network and below the third edges\n",
    "            c = pd.concat([geo_edgelist[geo_edgelist['user_id1'] == user][['user_id1', 'user_id2']], b], ignore_index = True)\n",
    "\n",
    "            G = nx.from_pandas_edgelist(c, 'user_id1', 'user_id2')\n",
    "            #r['clust' + str(dist)] = nx.average_clustering(G)\n",
    "            r['clust' + str(dist)] = nx.transitivity(G)\n",
    "    temp_list.append(r)\n",
    "\n",
    "\n",
    "clust_table = pd.DataFrame(temp_list)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point, save the data!!\n",
    "clust_table.to_csv(\"../data/clust_tab_top50_adam.csv.gz\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data prep (4) supported ties around home\n",
    "output : support_tab_top50.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reopen degree_tab\n",
    "degree_tab = pd.read_csv(\"../data/degree_tab_top50_adam.csv.gz\")\n",
    "users = list(set(list(degree_tab[\"user_id\"])))\n",
    "\n",
    "# edgelist with distance\n",
    "geo_edgelist = pd.read_csv(\"../data/geo_edgelist_top50_adam.csv.gz\")\n",
    "geo_edgelist = geo_edgelist[[\"user_id1\", \"user_id2\", \"dist_hh\" ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2707.3697669506073 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# supported ties around HOME\n",
    "# NOTE -- this process only works in case ties are present both ways\n",
    "start_time = time.time()\n",
    "\n",
    "temp_list = []\n",
    "\n",
    "for user in users:\n",
    "    r = {}\n",
    "    r['user_id'] = user\n",
    "    for dist in [1000, 3000, 5000, 10000]:\n",
    "        # get third edges\n",
    "        lista = list(geo_edgelist[(geo_edgelist['user_id1'] == user) & (geo_edgelist['dist_hh'] <= dist)]['user_id2'])\n",
    "        if len(lista) < 2:\n",
    "            r['support' + str(dist)] = np.nan\n",
    "        else:\n",
    "            a = geo_edgelist[geo_edgelist['user_id1'].isin(lista)]\n",
    "            b = a[a['user_id2'].isin(lista)][['user_id1', 'user_id2']]\n",
    "                       \n",
    "            r['support' + str(dist)] = len(b['user_id1'].unique()) / len(lista) \n",
    "    temp_list.append(r)\n",
    "\n",
    "\n",
    "support_table = pd.DataFrame(temp_list)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point, save the data!!\n",
    "support_table.to_csv(\"../data/supp_tab_top50_adam.csv.gz\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data prep (5) census data for regression\n",
    "output : census_for_regression.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census data\n",
    "census = pd.read_csv('../data/censusdata_top50_2012.csv')\n",
    "\n",
    "# short names for cbsas\n",
    "names = pd.read_csv('../data/cbsacode_shortname_tracts.csv', sep = \";\", index_col = 0)\n",
    "\n",
    "# home tract of users\n",
    "userinfo = pd.read_csv('../data/usageousers_data_export_with_tract_geoid_top50.csv.gz', index_col=0)\n",
    "userinfo = userinfo.loc[:,[\"user_id\", \"cbsacode\", \"tract_home\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create tract geoids\n",
    "def create_geoid(row):\n",
    "    state = str(int(row[\"state\"])).zfill(2)\n",
    "    county = str(int(row[\"county\"])).zfill(3)\n",
    "    tract = str(int(row[\"tract\"])).zfill(6)\n",
    "    return \"14000US\" +state+county+tract\n",
    "\n",
    "census['geoid'] = census.apply(create_geoid,axis=1)\n",
    "\n",
    "# add names\n",
    "census = pd.merge(census, names, on='geoid')\n",
    "\n",
    "# keep the key columns\n",
    "census = census[[\"geoid\", \"cbsacode\", \"short_name\", \"population\", \"education_bachelor\", \"income\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine info on users\n",
    "full_userinfo = pd.merge(userinfo, census, left_on=[\"cbsacode\", \"tract_home\"], right_on=[\"cbsacode\", \"geoid\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "full_userinfo.to_csv(\"../data/census_for_regression.csv.gz\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data prep (6) income of friends\n",
    "output : edgelist_geoinfo.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census data\n",
    "census = pd.read_csv('../data/censusdata_top50_2012.csv')\n",
    "\n",
    "# short names for cbsas\n",
    "names = pd.read_csv('../data/cbsacode_shortname_tracts.csv', sep = \";\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create tract geoids\n",
    "def create_geoid(row):\n",
    "    state = str(int(row[\"state\"])).zfill(2)\n",
    "    county = str(int(row[\"county\"])).zfill(3)\n",
    "    tract = str(int(row[\"tract\"])).zfill(6)\n",
    "    return \"14000US\" +state+county+tract\n",
    "\n",
    "census['geoid'] = census.apply(create_geoid,axis=1)\n",
    "\n",
    "# add names\n",
    "census = pd.merge(census, names, on='geoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    }
   ],
   "source": [
    "# geojson data, converted to geopandas dataframe\n",
    "tract_geoms = gpd.GeoDataFrame.from_features(\n",
    "    [json.loads(e.strip('\\n')) for e in open('../data/censustract_geoms_top50.geojson').readlines()]\n",
    ")\n",
    "\n",
    "# change projection\n",
    "init_crs = 4326 # lon,lat\n",
    "project_crs = 3857 # Cartesian systems\n",
    "tract_geoms.crs = {'init': 'epsg:' + str(init_crs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge census data and geometries of tracts\n",
    "tract_data = pd.merge(census[['geoid', 'cbsacode', 'short_name', 'population', 'education_bachelor', 'income']],\\\n",
    "    tract_geoms[['geometry', 'full_geoid']],\\\n",
    "    left_on='geoid', right_on='full_geoid', how='left')\n",
    "\n",
    "# drop those tracts where income < $1000\n",
    "tract_data = tract_data[(tract_data['income']>1000)]\n",
    "\n",
    "# median income by cbsacode\n",
    "tract_data['income_median'] = tract_data['cbsacode'].map(tract_data.groupby('cbsacode')['income'].median().to_dict())\n",
    "poor = (tract_data['income'] < tract_data[\"income_median\"])\n",
    "tract_data['poor'] = poor.astype(int).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edgelist with distance\n",
    "geo_edgelist = pd.read_csv(\"../data/geo_edgelist_top50.csv.gz\")\n",
    "\n",
    "# filter on important columns\n",
    "geo_edgelist = geo_edgelist[[\"cbsacode\", \"user_id1\", \"user_id2\", \"lon_home1\", \"lat_home1\", \"lon_home2\", \"lat_home2\", \"dist_hh\"]]\n",
    "\n",
    "# create geometry\n",
    "geo_edgelist[\"home_point1\"] = geo_edgelist.apply(lambda r: Point(r[\"lon_home1\"],r[\"lat_home1\"]), axis=1)\n",
    "geo_edgelist[\"home_point2\"] = geo_edgelist.apply(lambda r: Point(r[\"lon_home2\"],r[\"lat_home2\"]), axis=1)\n",
    "geo_edgelist = gpd.GeoDataFrame(geo_edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2711185, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_edgelist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "--- 189.4586217403412 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# spatial join 1\n",
    "start_time = time.time()\n",
    "\n",
    "tract_data = gpd.GeoDataFrame(tract_data)\n",
    "tract_data = tract_data.set_geometry('geometry')\n",
    "\n",
    "geo_edgelist = geo_edgelist.set_geometry('home_point1')\n",
    "geo_edgelist.crs = {'init': 'epsg:' + str(init_crs)}\n",
    "\n",
    "geo_edgelist = gpd.sjoin(geo_edgelist, tract_data, 'left', 'within')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up -- 1\n",
    "geo_edgelist = geo_edgelist[[\"user_id1\", \"user_id2\", \"dist_hh\", \"home_point2\", \"geoid\", \"population\", \"education_bachelor\", \"income\", \"income_median\", \"poor\"]]\n",
    "geo_edgelist.columns = [\"user_id1\", \"user_id2\", \"dist_hh\", \"home_point2\", \"tract_id1\", \"population1\", \"education_bachelor1\", \"income1\", \"income_median1\", \"poor1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "--- 186.69965505599976 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# spatial join 2\n",
    "start_time = time.time()\n",
    "\n",
    "tract_data = gpd.GeoDataFrame(tract_data)\n",
    "tract_data = tract_data.set_geometry('geometry')\n",
    "\n",
    "geo_edgelist = geo_edgelist.set_geometry('home_point2')\n",
    "geo_edgelist.crs = {'init': 'epsg:' + str(init_crs)}\n",
    "\n",
    "geo_edgelist = gpd.sjoin(geo_edgelist, tract_data, 'left', 'within')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up -- 2\n",
    "geo_edgelist = geo_edgelist[[\"cbsacode\", \"short_name\", \"user_id1\", \"user_id2\", \"dist_hh\", \"tract_id1\", \"population1\", \"education_bachelor1\", \"income1\", \"income_median1\", \"poor1\", \"geoid\", \"population\", \"education_bachelor\", \"income\", \"income_median\", \"poor\"]]\n",
    "geo_edgelist = geo_edgelist.rename(columns={\"geoid\": \"tract_id2\", \"population\": \"population2\", \"education_bachelor\": \"education_bachelor2\", \"income\": \"income2\", \"income_median\": \"income_median2\", \"poor\": \"poor2\"})\n",
    "\n",
    "# sort\n",
    "geo_edgelist = geo_edgelist.sort_values(by=['user_id1', 'user_id2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "geo_edgelist.to_csv(\"../data/edgelist_geoinfo.csv.gz\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### intermission ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring back the edgelist with income data\n",
    "edge_table = pd.read_csv(\"../data/edgelist_geoinfo.csv.gz\")\n",
    "\n",
    "# filter for edges inside 10 km\n",
    "edge_table = edge_table[edge_table[\"dist_hh\"]<=10000]\n",
    "\n",
    "# degree data\n",
    "degree_tab = pd.read_csv(\"../data/degree_tab_top50.csv.gz\")\n",
    "pr_friends = degree_tab[[\"user_id\", \"cbsacode\", \"short_name\", \"poor\", \"degree\"]].set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create nr poor ties var\n",
    "temp = edge_table[edge_table[\"poor2\"]==1]\n",
    "pr_friends[\"poor_ties\"] = pr_friends.index.map(temp.groupby(\"user_id1\")[\"user_id2\"].agg(\"count\").to_dict())\n",
    "pr_friends = pr_friends.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# share of poor/rich ties\n",
    "pr_friends[\"share_poor_ties\"] = pr_friends[\"poor_ties\"] / pr_friends[\"degree\"]\n",
    "pr_friends[\"share_rich_ties\"] = 1 - (pr_friends[\"poor_ties\"] / pr_friends[\"degree\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users with min 10 degree from degree_tab\n",
    "users = list(set(list(degree_tab[\"user_id\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering between POOR / RICH friends\n",
    "start_time = time.time()\n",
    "\n",
    "temp_list = []\n",
    "pr = {\"poor\" : 1, \"rich\" : 0}\n",
    "\n",
    "for user in users:\n",
    "    r = {}\n",
    "    r['user_id'] = user\n",
    "\n",
    "    for i in pr: # 1 : poor, 0 : rich\n",
    "        lista = list(edge_table[(edge_table['user_id1'] == user) & (edge_table['poor2'] == pr[i])]['user_id2'])\n",
    "        if len(lista) < 2:   # in case the user does not have at least 2 connections\n",
    "            r['clust_' + str(i)] = np.nan\n",
    "        else:\n",
    "            a = edge_table[edge_table['user_id1'].isin(lista)]\n",
    "            b = a[a['user_id2'].isin(lista)][['user_id1', 'user_id2']]\n",
    "            # get df with ego network and below the third edges\n",
    "            c = pd.concat([edge_table[edge_table['user_id1'] == user][['user_id1', 'user_id2']], b], ignore_index = True)\n",
    "\n",
    "            G = nx.from_pandas_edgelist(c, 'user_id1', 'user_id2')\n",
    "            r['clust_' + str(i)] = nx.transitivity(G)\n",
    "    temp_list.append(r)\n",
    "\n",
    "\n",
    "clust_table = pd.DataFrame(temp_list)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering info to pr_friends table\n",
    "pr_friends = pd.merge(pr_friends, clust_table, on=\"user_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support between POOR / RICH friends\n",
    "# NOTE -- this process only works in case ties are present both ways\n",
    "start_time = time.time()\n",
    "\n",
    "temp_list = []\n",
    "pr = {\"poor\" : 1, \"rich\" : 0}\n",
    "\n",
    "for user in users:\n",
    "    r = {}\n",
    "    r['user_id'] = user\n",
    "\n",
    "    for i in pr: # 1 : poor, 0 : rich\n",
    "        # get third edges\n",
    "        lista = list(edge_table[(edge_table['user_id1'] == user) & (edge_table['poor2'] == pr[i])]['user_id2'])\n",
    "        if len(lista) < 2:\n",
    "            r['support_' + str(i)] = np.nan\n",
    "        else:\n",
    "            a = edge_table[edge_table['user_id1'].isin(lista)]\n",
    "            b = a[a['user_id2'].isin(lista)][['user_id1', 'user_id2']]\n",
    "                       \n",
    "            r['support_' + str(i)] = len(b['user_id1'].unique()) / len(lista) \n",
    "    temp_list.append(r)\n",
    "\n",
    "\n",
    "support_table = pd.DataFrame(temp_list)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering info to pr_friends table\n",
    "pr_friends = pd.merge(pr_friends, support_table, on=\"user_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "pr_friends.to_csv(\"../data/pr_friends_stats.csv.gz\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
